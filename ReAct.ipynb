{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+KDr7AxUxTRDFh85taXAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adyypower/LLMs-Model/blob/main/ReAct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1kGvVpeQ9bGM"
      },
      "outputs": [],
      "source": [
        "# 1. Install necessary libraries\n",
        "!pip install -qU langchain langchain_google_genai langgraph\n",
        "\n",
        "# 2. Set up your Google API Key\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Make sure you have created a secret named \"GOOGLE_API_KEY\" in your Colab environment\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Import required modules from LangChain and LangGraph\n",
        "from typing import Annotated, Sequence, TypedDict\n",
        "\n",
        "from langchain_core.messages import BaseMessage , ToolMessage , SystemMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n"
      ],
      "metadata": {
        "id": "nOL_HkmZ-5rs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages:Annotated[Sequence[BaseMessage],add_messages]"
      ],
      "metadata": {
        "id": "X6k5s_AI_EFN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "\n",
        "def add(a:int,b:int):\n",
        "  \"\"\" this is an additin function that add 2 numberr together\"\"\"\n",
        "  return a+b"
      ],
      "metadata": {
        "id": "bkMUHnQm_fYs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def multiply(a: int, b: int):\n",
        "    \"\"\"Multiplication function\"\"\"\n",
        "    return a * b\n"
      ],
      "metadata": {
        "id": "6nv9xTisNBf5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def subtract(a: int, b: int):\n",
        "    \"\"\"Subtraction function\"\"\"\n",
        "    return a - b"
      ],
      "metadata": {
        "id": "Vn85hWgBND3Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [add,subtract,multiply]"
      ],
      "metadata": {
        "id": "JAQK_57t_tYa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\").bind_tools(tools)"
      ],
      "metadata": {
        "id": "ul_I_4mH_vL8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_call(state:AgentState) -> AgentState:\n",
        "    system_prompt = SystemMessage(content=\n",
        "        \"You are my AI assistant, please answer my query to the best of your ability.\"\n",
        "    )\n",
        "    response = model.invoke([system_prompt] + state[\"messages\"])\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "opob8M3_AHbs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def should_continue(state:AgentState)->AgentState:\n",
        "  messages = state[\"messages\"]\n",
        "  last_message = messages[-1]\n",
        "  if not last_message.tool_calls:\n",
        "    return \"end\"\n",
        "  else:\n",
        "    return \"continue\""
      ],
      "metadata": {
        "id": "BTd6IAliBxF6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"our_agent\", model_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e94XUoc0CPPj",
        "outputId": "a3ea16d4-1b9d-41e5-a355-1bf1f54ee703"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7adb41829c10>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_node = ToolNode(tools=tools)\n",
        "graph.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lwJ326C1Hjkk",
        "outputId": "305e4381-c5d2-40bb-91af-6df434069155"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7adb41829c10>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.set_entry_point(\"our_agent\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"our_agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"continue\": \"tools\",\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAb-FOUJH5UH",
        "outputId": "180b5543-3160-451f-baf3-9a6a8efd60a6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7adb41829c10>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_edge(\"tools\",\"our_agent\")\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "DFYTJeknDXwI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_stream(stream):\n",
        "    for s in stream:\n",
        "        message = s[\"messages\"][-1]\n",
        "        message.pretty_print()\n"
      ],
      "metadata": {
        "id": "faMOqZ7CDiW4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Add 40 + 12 and then multiply result by 6 then also tell me a joke please.\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "print_stream(app.stream(inputs, stream_mode=\"values\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D91VNKmrIBlS",
        "outputId": "d79551eb-e5f3-4921-90fc-9e5c02e2baae"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Add 40 + 12 and then multiply result by 6 then also tell me a joke please.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  add (99d6ef70-15a9-4abe-9504-34d5241f4c7f)\n",
            " Call ID: 99d6ef70-15a9-4abe-9504-34d5241f4c7f\n",
            "  Args:\n",
            "    a: 40\n",
            "    b: 12\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "52\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  multiply (abde0eeb-84a6-4e7d-84fa-00bb12a2a76b)\n",
            " Call ID: abde0eeb-84a6-4e7d-84fa-00bb12a2a76b\n",
            "  Args:\n",
            "    a: 52\n",
            "    b: 6\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: multiply\n",
            "\n",
            "312\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The sum of 40 and 12 is 52. When you multiply 52 by 6, the result is 312.\n",
            "\n",
            "Here's a joke for you: Why don't scientists trust atoms? Because they make up everything!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YU4EIccJMdIj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}