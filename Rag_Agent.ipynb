{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbqHX9lI5yXnejdzGZrTqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adyypower/LLMs-Model/blob/main/Rag_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HahrVErliT7A",
        "outputId": "af8772e3-595e-421a-9abc-60fbab62d3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install the required packages for our project\n",
        "!pip install -qU \\\n",
        "    langchain \\\n",
        "    langchain-openai \\\n",
        "    langchain-google-genai \\\n",
        "    langchain-chroma \\\n",
        "    langgraph \\\n",
        "    langchain-community \\\n",
        "    pypdf \\\n",
        "    python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-huggingface sentence-transformers"
      ],
      "metadata": {
        "id": "sOZvq8Uik_sf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from operator import add as add_messages\n",
        "\n",
        "# Import LangChain and related modules\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # <-- Import Google's model\n",
        "from langchain_openai import OpenAIEmbeddings # <-- We still need this for embeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Set the API keys from Colab's secrets\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "# Keep the OpenAI key if you still plan to use their embedding model\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "4MtJmjMCjh_N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Chat LLM with Gemini 1.5 Flash\n",
        "# We set temperature=0 to make the model's output more deterministic\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "\n",
        "print(\"Using Hugging Face model for embeddings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSXY5_ZZj6EE",
        "outputId": "d701be75-3d9d-40e1-b9c8-8bc43b6a95fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Hugging Face model for embeddings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# --- Upload your PDF file ---\n",
        "print(\"Please upload your PDF file.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename of the uploaded file\n",
        "if not uploaded:\n",
        "    raise ValueError(\"No file was uploaded. Please run the cell again and upload your PDF.\")\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "print(f\"\\nSuccessfully uploaded '{pdf_path}'\")\n",
        "\n",
        "\n",
        "# --- Load and Chunk the PDF ---\n",
        "pdf_loader = PyPDFLoader(pdf_path)\n",
        "\n",
        "try:\n",
        "    pages = pdf_loader.load()\n",
        "    print(f\"PDF has been loaded and has {len(pages)} pages.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading PDF: {e}\")\n",
        "    raise\n",
        "\n",
        "# Initialize the text splitter for chunking\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "# Split the document pages into chunks\n",
        "pages_split = text_splitter.split_documents(pages)\n",
        "print(f\"Document split into {len(pages_split)} chunks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "YdzYDVipj9t1",
        "outputId": "b32dee8f-1fd4-4e9a-b52f-f2d3666887e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PDF file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1bfb595d-eb4f-4594-bfd5-8208e71c660c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1bfb595d-eb4f-4594-bfd5-8208e71c660c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving attention_paper.pdf to attention_paper (1).pdf\n",
            "\n",
            "Successfully uploaded 'attention_paper (1).pdf'\n",
            "PDF has been loaded and has 15 pages.\n",
            "Document split into 52 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory to persist the vector database and a collection name\n",
        "persist_directory = \"db\"\n",
        "collection_name = \"stock_market\"\n",
        "\n",
        "try:\n",
        "    # Create the Chroma vector store from the document chunks\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=pages_split,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=persist_directory,\n",
        "        collection_name=collection_name\n",
        "    )\n",
        "    print(\"Successfully created ChromaDB vector store!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up ChromaDB: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Create the retriever from the vector store\n",
        "# It will return the top 5 most similar document chunks (k=5)\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 5}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2AALixBkfGQ",
        "outputId": "b8e234e4-1b4b-42d9-9b85-8627a8ef270d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created ChromaDB vector store!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def retriever_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    This tool searches and returns the information from the research paper Attention all you need document.\n",
        "    \"\"\"\n",
        "\n",
        "    docs = retriever.invoke(query)\n",
        "\n",
        "    if not docs:\n",
        "        return \"I found no relevant information in the paper attention all you need document.\"\n",
        "\n",
        "    results = []\n",
        "    for i, doc in enumerate(docs):\n",
        "        results.append(f\"Document {i+1}:\\n{doc.page_content}\")\n",
        "\n",
        "    return \"\\n\\n\".join(results)\n",
        "\n",
        "\n",
        "tools = [retriever_tool]\n",
        "\n",
        "llm = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "rLkpNYnEmfwo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages:Annotated[Sequence[BaseMessage], add_messages]\n",
        ""
      ],
      "metadata": {
        "id": "PWBwouDtqgLc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def should_continue(State:AgentState):\n",
        "  \"\"\"check if the last message contains tool calls\"\"\"\n",
        "  result = State['messages'][-1]\n",
        "  return hasattr(result, 'tool_calls') and len(result.tool_calls)>0"
      ],
      "metadata": {
        "id": "z49xVs8Pqr9J"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You are an intelligent AI assistant who answers questions about the research paper attention all you need based on the PDF document loaded into your knowledge base.\n",
        "Use the retriever tool available to answer questions about the stock market performance data. You can make multiple calls if needed.\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "Please always cite the specific parts of the documents you use in your answers.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "trPHRh6RsDbo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools_dict = {our_tool.name: our_tool for our_tool in tools} # Creating a dictionary of our tools"
      ],
      "metadata": {
        "id": "S_bIIw7Br9Mm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_llm(state: AgentState) -> AgentState:\n",
        "    \"\"\"Function to call the LLM with the current state.\"\"\"\n",
        "    messages = list(state['messages'])\n",
        "    messages = [SystemMessage(content=system_prompt)] + messages\n",
        "    message = llm.invoke(messages)\n",
        "    return {'messages': [message]}"
      ],
      "metadata": {
        "id": "zYcma96BsqNo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_action(state: AgentState) -> AgentState:\n",
        "    \"\"\"Execute tool calls from the LLM's response.\"\"\"\n",
        "\n",
        "    tool_calls = state['messages'][-1].tool_calls\n",
        "    results = []\n",
        "    for t in tool_calls:\n",
        "        print(f\"Calling Tool: {t['name']} with query: {t['args'].get('query', 'No query provided')}\")\n",
        "\n",
        "        if not t['name'] in tools_dict: # Checks if a valid tool is present\n",
        "            print(f\"\\nTool: {t['name']} does not exist.\")\n",
        "            result = \"Incorrect Tool Name, Please Retry and Select tool from List of Available tools.\"\n",
        "\n",
        "        else:\n",
        "            result = tools_dict[t['name']].invoke(t['args'].get('query', ''))\n",
        "            print(f\"Result length: {len(str(result))}\")\n",
        "\n",
        "\n",
        "        # Appends the Tool Message\n",
        "        results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
        "\n",
        "    print(\"Tools Execution Complete. Back to the model!\")\n",
        "    return {'messages': results}"
      ],
      "metadata": {
        "id": "vHFajwj0tWZC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"llm\", call_llm)\n",
        "graph.add_node(\"retriever_agent\", take_action)\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"llm\",\n",
        "    should_continue,\n",
        "    {True: \"retriever_agent\", False: END}\n",
        ")\n",
        "graph.add_edge(\"retriever_agent\", \"llm\")\n",
        "graph.set_entry_point(\"llm\")\n",
        "\n",
        "rag_agent = graph.compile()"
      ],
      "metadata": {
        "id": "qg5HYPhCvXqn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def running_agent():\n",
        "  log_file_path = \"conversation_log.txt\"\n",
        "  while True:\n",
        "    user_input = input(\"\\n what is your question about paper: \")\n",
        "    if user_input.lower() in [\"exit\",\"quit\"]:\n",
        "      break\n",
        "    messages = [HumanMessage(content = user_input)]\n",
        "\n",
        "    result = rag_agent.invoke({\"messages\":messages})\n",
        "\n",
        "    print(\"\\n===== ANSWER=====\")\n",
        "\n",
        "    print(result['messages'][-1].content)\n",
        "    try:\n",
        "        with open(log_file_path, 'a', encoding='utf-8') as f:\n",
        "                f.write(f\"Q: {user_input}\\n\")\n",
        "                f.write(f\"A: {result['messages'][-1].content}\\n\")\n",
        "                f.write(\"-\" * 20 + \"\\n\") # Adds a separator\n",
        "    except Exception as e:\n",
        "            print(f\"\\nError writing to log file: {e}\")"
      ],
      "metadata": {
        "id": "k6fzPcCtvc77"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwurIr5swJ0s",
        "outputId": "56a8843a-ef0a-4f0f-8198-da5fb12ef83a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " what is your question about paper: what is this paper about \n",
            "Calling Tool: retriever_tool with query: what is this paper about\n",
            "Result length: 3640\n",
            "Tools Execution Complete. Back to the model!\n",
            "\n",
            "===== ANSWER=====\n",
            "The provided documents do not contain an abstract or introduction that directly states the paper's main topic. However, based on the snippets, it appears to be a research paper related to **Natural Language Processing (NLP)**, specifically focusing on **attention mechanisms** in neural networks.\n",
            "\n",
            "Here's what the snippets suggest:\n",
            "\n",
            "*   **Encoder-Decoder Models:** Document 3 describes an encoder-decoder structure where an input sequence is mapped to continuous representations, and then a decoder generates an output sequence one element at a time, consuming previously generated symbols as input. This is a common architecture in sequence-to-sequence tasks like machine translation.\n",
            "*   **Attention Mechanisms:** Document 4 shows \"Attention Visualizations\" and discusses \"long-distance dependencies in the encoder self-attention.\" It highlights how attention heads can focus on specific parts of the input, like the verb \"making\" and its related phrase \"more difficult.\" This strongly indicates that the paper is exploring and likely proposing or analyzing an attention mechanism.\n",
            "*   **Neural Machine Translation (NMT):** Document 2 mentions \"Neural machine translation in linear time\" in a citation, suggesting a connection to NMT.\n",
            "*   **Tensor2Tensor:** Document 5 mentions \"implementing tensor2tensor,\" which is an open-source library for neural network models, particularly for sequence-to-sequence tasks, further supporting the NLP and neural network focus.\n",
            "\n",
            "Given the title \"Attention All You Need\" (which is not explicitly in the provided snippets but is the name of the paper you asked about), and the content of the snippets, the paper is very likely about **Transformers**, a novel neural network architecture that relies solely on attention mechanisms, dispensing with recurrence and convolutions.\n",
            "\n",
            " what is your question about paper: what is decoder\n",
            "Calling Tool: retriever_tool with query: decoder\n",
            "Result length: 4152\n",
            "Tools Execution Complete. Back to the model!\n",
            "\n",
            "===== ANSWER=====\n",
            "The decoder is a component of the Transformer model architecture. Its primary function is to generate an output sequence of symbols one element at a time, given a continuous representation (z) from the encoder. The decoder operates in an auto-regressive manner, meaning it consumes previously generated symbols as additional input when generating the next symbol (Document 1).\n",
            "\n",
            "Here are some key characteristics of the decoder:\n",
            "\n",
            "*   **Structure:** The decoder is composed of a stack of N=6 identical layers. Each layer has three sub-layers: two similar to the encoder (multi-head self-attention and a position-wise fully connected feed-forward network) and a third sub-layer that performs multi-head attention over the output of the encoder stack (Document 2, Document 4).\n",
            "*   **Residual Connections and Layer Normalization:** Similar to the encoder, the decoder employs residual connections around each sub-layer, followed by layer normalization (Document 2).\n",
            "*   **Masked Self-Attention:** The self-attention sub-layer in the decoder is modified to prevent positions from attending to subsequent positions. This masking, combined with the output embeddings being offset by one position, ensures that predictions for position *i* can only depend on known outputs at positions less than *i*. This is crucial for preserving the auto-regressive property (Document 2, Document 5).\n",
            "*   **Encoder-Decoder Attention:** The \"encoder-decoder attention\" layers in the decoder use queries from the previous decoder layer and memory keys and values from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence, mimicking typical encoder-decoder attention mechanisms (Document 3).\n",
            "\n",
            " what is your question about paper: exit\n"
          ]
        }
      ]
    }
  ]
}